---
title: "Predicting Car Crashes Caused by Alcohol Using Logistic Regression"
author: "Li, Jie; Wang, Yan; Zhang, Yihan"
date: "11/2o/2022"
output:
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
    theme: paper
    fig_caption: yes
  pdf_document: default
editor_options: 
  markdown: 
    wrap: sentence
---

<link rel="stylesheet" href="css/styles.css">

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=FALSE, results="hide", message=FALSE, warning=FALSE)
```

```{r set-up}

# Several libraries and util functions from my GitHub
source("https://raw.githubusercontent.com/Leejere/r-setup/main/r_setup.r")
library(gmodels)
```

# Introduction

-   State the problem, the importance of the problem, and the setting of the analysis (Philadelphia).
-   Speculate as to **why** the predictors we are using might be associated with the dependent variable.
-   Indicate the tool (R).

# Methods

## Constructing and interpreting the model

In an OLS regression, we dealt with dependent variables whose values were continuous with a reasonably large range, so that the model could be explained as one unit's change of a predictor correlating with how many units' change of the dependent variable (holding other variables constant).
However, this explanation no longer applies when the dependent variable is binary, as it only takes values of either 0 or 1.

The logistic regression method works around this problem by turning the $y$ in the equation from *binary* to continuous *probability*.
In this way, we may say that one unit's change of a predictor is correlated with certain increase or decrease in the probability of the dependent variable being "True".
However, this brings another problem, as probability only ranges from 0 to 1, whereas the OLS regression is a linear model in which the $y$ should have no lower and upper bounds.
To solve this problem, we can construct a new variable, $ln\frac{p}{1-p}$, in which $p$ is the probability of the dependent variable being "True" ($p=P(drink=1)$).
The ratio of "True" probability against "False" probability is called the *odds*.
By wrapping the *odds* inside of a log-transform, we have successfully turned the scope of $y$ to from $-\infty$ to $\infty$.

The translator function of $ln(\frac{p}{1-p})$ is called the the *logit function*.
As the input probability approaches zero, the output logit odds approaches $-\infty$; conversely, if the input probability is close to 1, the output logit odds reaches $\infty$.
In this way, the binary variable is successfully transformed into a continuous one with an infinite scope, so that we can use it as the new $y$ and fit a model.

The final equation for the logistic model is written as follows:

$$
ln(\frac{p}{1-p})=\beta_0 + \beta_1\cdot fatal\_injury + \beta_2\cdot overturned + \beta_3\cdot phone + \beta_4\cdot speeding + \beta_5\cdot aggressive + \beta_6\cdot teen\_driver + \beta_7\cdot senior\_driver + \epsilon
$$

where $ln(\frac{p}{1-p})$ is the "log odds" where $p$ is the probability of the crash being caused by alcohol, $\beta_0$ is the intercept coefficient, $\beta_1$ to $\beta_n$ are the coefficients of the 7 predictors, and $\epsilon$ is the residual.
The model is estimated through the Maximum Likelihood Method.

We determine whether each coefficient is significant through hypothesis testing.
For each coefficient $\beta_i$, the *null hypothesis* ($H_0$) is that $\beta_i=0$.
As $\beta_i$ has a normal distribution with a standard deviation of $\sigma_{\beta_i}$, we may calculate a Z-score through $\frac{\hat\beta_i - 0}{\sigma_{\beta_i}}$ where $\hat\beta_i$ is the coefficient estimated from the model.
If the p-value associated with the Z-score goes under 0.05, we reject the null hypothesis for the *alternative hypothesis* that $\beta_i\neq0$.

To interpret the coefficients, most statisticians use a concept of *odds ratio*, which is calculated by exponentiating the $\beta$ coefficients ($e^{\beta_i}$).
For every unit of change in the predictor $\x_i$, the odds ratio increases by a factor of $e^{\beta_i}$.

It should be noted that the logistic model only outputs the estimated *probabilities*; and to obtain the predictions for the dependent variable, we need to determine a "cutoff probability", above which the dependent variable is predicted to be true and below which false.

## Model goodness of fit

How do we determine the goodness of fit of a logistic regression model?
As in the OLS model, $R^2$ can be estimated, but it no longer bears the interpretation as the ratio of variance explained by the model.
To compare the goodness of fit of multiple nested models, we may use the Akaike Information Criterion, a smaller value of which indicates a better fit compared to the baseline model.

As mentioned in the previous section, the predictions for the dependent variable depend on the "cutoff probability" that we set.
An observation is predicted to be true ($\hat y=1$), if the estimated probability $p$ is higher than the threshold, and vice versa.
Then, each observation is categorized into one of the four following categories:

|                    | Observed True      | Observed False     |
|--------------------|--------------------|--------------------|
| Predicted Positive | TP: True Positive  | FP: False Positive |
| Predicted Negative | FN: False Negative | TN: True Negative  |

The goal is to find the best cutoff value that maximizes TP and TN, while minimizing FP and FN.
Specifically, - *Sensitivity*, or *True Positive Rate*, stands for how well the model is able to pick out the True observations, and is calculated as $\frac{TP}{TP+FN}$.
- *Specificity*, or *True Negative Rate* stands for how well the model accurately predicts false values, and is calculated as $\frac{TN}{TN+FP}$.

Deciding on the right cutoff value is often a trade-off process.
If the cutoff value is set to be relatively high, then fewer observations will be predicted as true.
The sensitivity may lower, but the specificity increases.
On the other hand, a lower cutoff value categorizes more observations to be true, often increasing sensitivity but lowering specificity.
This trade-off process can be visualized using the *ROC curve*, in which the x-axis stands for false positive rate, or one minus specificity, and the y-axis stands for true positive rate or sensitivity.
As you lower the cutoff value, the false positive rate goes up, whereas the true positive rate also goes up, forming a curve depicted as follows:

![roc-diagram](./pic/roc-curve-diagram.png)

This diagram can help us find a combination of reasonably high sensitivity and specificity, i.e., a point as close to the upper-left corner as possible.
A few methods exist the determine this point: - By maximizing the sum of sensitivity and specificity, or the *Youden Index*.
- By minimizing the distance on the ROC plot from the curve to the upper left corner.

If we have a good model, all the points on the ROC curve (no matter the cutoff value) will be generally closer to the upper-left corner, and the area under the curve will be greater.
Therefore, the Area Under the Curve, or AUC, is another criterion of the goodness of fit of the logistic model.

## Model Assumptions

Like the OLS model, the logistic model also has a number of assumptions required of the data.
These assumptions are:

-   The dependent variable is binary.

-   The observations are independent from each other.

-   There is no severe multi-collinearity among the predictors.

-   Large samples size is required, as the model is estimated through the Maximum Likelihood Estimation method.

Unlike the OLS, however, the logistic regression model makes no assumption that the relationship between the dependent variable and each predictor is normal.
It does not require homoscedasticity, nor the normality of the distribution of residuals.

## Exploratory analysis before a logistic regression

Before running a logistic regression, statisticians often carry out a series of exploratory analysis.

**Cross-tabulation between the dependent variable and categorical predictors**.
We can cross-tabulate all the observations into groups, each group being a combination of the true/false value of the dependent and a class of the predictor.
A *chi-square test* is performed.
Its null hypothesis is that there is no significant difference in terms of outcome (dependent variable) between the classes, as opposed to the alternative hypothesis of there being a significant difference.
If the null hypothesis stands, then the chi-square value should be of chi-square distribution.
If the p-value of the observed chi-square is reasonably small (i.e., smaller than 0.05), then we may reject the null hypothesis for the alternative hypothesis and state that the predictor is indeed correlated with the dependent variable.

**Independent-samples T-tests**.
To examine the correlation between dependent variable and a continuous predictor, we may calculate the mean value of the predictor by the binary outcome.
The true or false of the binary outcome essentially divides all the observations into two samples, and then we can test whether there is a significant difference between the two samples through an independent-samples T-test.
The null hypothesis for this test is that there is no significant difference between the two samples.
If such hypothesis stands, then the difference of the two sample means will be of T-distribution.
If the observed T-score is associated with a p-value lower than 0.05, then we reject the null hypothesis for the alternative hypothesis that there is significant difference between the two samples, and therefore the predictor is correlated with the dependent variable.

# Data exploration

Before performing the logistic regressions, we first explored the relationship between the predictors and the dependent variable, and between the predictors themselves.
The below code chunk imports the data and sets up the variable names for the imported data frame.

```{r import}

# Import data
df = read.csv("data/Logistic Regression Data.csv") %>%
  dplyr::select(record_id = CRN, # Crash record number
                drink = DRINKING_D, # Drinking driver indicator (boolean)
                fatal_injury = FATAL_OR_M, # Crash resulted in fatality or major injury (boolean)
                overturned = OVERTURNED, # Crash involved an overturned vehicle (boolean)
                phone = CELL_PHONE, # Driver was using a cell phone (boolean)
                speeding = SPEEDING, # Crash involved speeding car (boolean)
                aggressive = AGGRESSIVE, # Crash involved aggressive driving (boolean)
                teen_driver = DRIVER1617, # Car involved at least one driver who was 16 or 17 years old (boolean)
                senior_driver = DRIVER65PLUS, # Crash involved at least one driver was was at least 65 years old (boolean)
                pct_bachelor = PCTBACHMOR, # Pct residents in CBG with bachelor's degree or higher
                md_hh_income = MEDHHINC, # Median houshold income of CBG
                )

# Dictionary of var names to their real names
names_dict = 
  c("record_id" = "Record ID",
    "drink" = "Involved drnking driver",
    "phone" = "Involved phone usage",
    "fatal_injury" = "Involved fatality or major injury",
    "overturned" = "Involved overturned vehicle",
    "speeding" = "Involved speeding car",
    "aggressive" = "Involved aggressive driving",
    "teen_driver" = "Involved driver 16 to 17 years old",
    "senior_driver" = "Involved driver 65 years or older",
    "pct_bachelor" = "Pct residents in CBG w/ at least bachelor's degree",
    "md_hh_income" = "Median houshold income of CBG")

```

## The dependent variable

Let's first take a quick look at the dependent variable through Table 1.
5.7% of all the crashes in the data set involved a drinking driver and therefore possibly caused by drinking.
The other 94.3% of the crashes did not involve a drinking driver.

```{r dv-tab, results="asis"}

# Tabulation of the dependent variable
table(df$drink) %>%
  as.data.frame() %>%
  mutate("Drinking Status" = ifelse(Var1 == 1, "Involved drinking driver",
                                  "Did not involve drinking driver")) %>%
  dplyr::select("Drinking Status", Freq) %>%
  mutate(Proportion = (Freq * 100 / sum(Freq)) %>% round(1) %>% paste0("%")) %>%
  kable(caption = "Table 1. Tabulation of the dependent variable") %>%
  kable_classic(full_width=FALSE, html_font="Cambria")
```

## The binary predictors

In this section, we explored the relationship between the dependent variable and the 7 *binary* predictors:

-   `fatal_injury`: involved fatality or major injuries.
-   `overturned`: involved overturned vehicle.
-   `phone`: involved cell-phone usage.
-   `speeding`: involved speeding vehicle.
-   `aggressive`: involved aggressive driving.
-   `teen_driver`: involved driver of 16 to 17 years old.
-   `senior_driver`: involved driver 65 years or older.

The below two code chunks performs a cross-tabulation between the dependent variable and the 7 binary predictors, as shown in Table 2.
The percentages indicate what percentages of crashes (either involving a drinking driver or not) are "true" in their respective predictors.
The last column is the p-value corresponding to the $\chi^2$ test of the dependent variable and each predictors.

```{r cross-tabs, message=FALSE}

# Sum all counts and percentages
sum_table = df %>%
  dplyr::select(-record_id, -pct_bachelor, -md_hh_income) %>%
  group_by(drink) %>%
  summarise_all(c(sum=sum, avg=mean)) %>% # sum means total count, avg means percentage of of positive values
  t() %>%
  as.data.frame()

# Get rid of first row, dependent variable
sum_table = sum_table[-1,] 

# Organize the table
sum_table = sum_table %>%
  mutate(index = rownames(sum_table),
         var_name = index %>% substring(1, nchar(index) - 4),
         func_name = index %>% substring(nchar(index) - 2, nchar(index))) %>%
  rename(no_alcohol = V1, alcohol = V2) %>%
  dplyr::select(no_alcohol, alcohol, var_name, func_name)

sum_table_sum = sum_table %>% filter(func_name == "sum") %>%
  dplyr::select(no_alcohol, alcohol, var_name) %>%
  rename(count_no_alcohol = no_alcohol, count_alcohol = alcohol)
sum_table_avg = sum_table %>% filter(func_name == "avg") %>%
  dplyr::select(no_alcohol, alcohol, var_name) %>%
  mutate(no_alcohol = (no_alcohol * 100) %>% round(1) %>% paste0("%"),
         alcohol = (alcohol * 100) %>% round(1) %>% paste0("%")) %>%
  rename(pct_no_alcohol = no_alcohol, 
         pct_alcohol = alcohol)

output = sum_table_sum %>%
  left_join(sum_table_avg, on = "var_name") %>%
  dplyr::select(var_name, count_no_alcohol, pct_no_alcohol, count_alcohol, pct_alcohol)

# Organize final output suitable for kable
rownames(output) = names_dict[output$var_name] %>% unname()
output = output %>% dplyr::select(-var_name)

```

```{r chi-squares, results="asis"}

var_list = c("fatal_injury", "overturned", "phone", "speeding", "aggressive",
             "teen_driver", "senior_driver")
chisq_list = c()
for(var in var_list) {
  this_test = chisq.test(df[[var]], df$drink)
  this_p = this_test$p.value %>% round(3)
  chisq_list = c(chisq_list, this_p)
}

output = output %>% cbind(chisq_list) %>%
  rename("Chi-Square p-value" = chisq_list)

colnames(output) = c("N", "%", "N", "%", "Chi-square p-value")

output %>%
  kable(caption = "Table 2. Cross tabulations of the dependent variable and binary predictors") %>%
  add_header_above(c(" ", "No alcohol involved" = 2, "Alcohol involved" = 2, "Chi-square test" = 1)) %>%
  kable_classic(full_width=FALSE, html_font="Cambria")
```

The chi-square test results show that apart from cell-phone usage, all the other binary predictors are significant correlated with the dependent variable.

## The continuous variables

Next, we explored the dependent variable and the two continuous predictors: - `pct_bachelor`: percentage of residents with a bachelor's degree or higher in the census block group (CBG) where the crash took place.
- `md_hh_income`: median houshold income of the census block group (CBG) where the crash took place.

The below two code chunks perform a tabulation between the dependent variable and the two predictors (Table 3.), summarizing the mean and standard deviation of each predictor, categorized by the dependent variable (involved a drinking driver or not).
The last column shows the p-value from the independent-samples T-Test of each predictor by the dependent variable.

```{r tab-continuous, message=FALSE}
sum_table_2 = df %>%
  mutate(md_hh_income = md_hh_income / 1000) %>%
  dplyr::select(drink, pct_bachelor, md_hh_income) %>%
  group_by(drink) %>%
  summarise_all(c(avg=mean, std=sd)) %>% # sum means total count, avg means percentage of of positive values
  t() %>%
  as.data.frame()

# Get rid of first row, dependent variable
sum_table_2 = sum_table_2[-1,]

# Organize the table
sum_table_2 = sum_table_2 %>%
  mutate(index = rownames(sum_table_2),
         var_name = index %>% substring(1, nchar(index) - 4),
         func_name = index %>% substring(nchar(index) - 2, nchar(index))) %>%
  rename(no_alcohol = V1, alcohol = V2) %>%
  dplyr::select(no_alcohol, alcohol, var_name, func_name)

sum_table_std = sum_table_2 %>% filter(func_name == "std") %>%
  dplyr::select(no_alcohol, alcohol, var_name) %>%
  mutate(no_alcohol = no_alcohol %>% round(2),
         alcohol = alcohol %>% round(2)) %>%
  rename(count_no_alcohol = no_alcohol, count_alcohol = alcohol)

sum_table_avg = sum_table_2 %>% filter(func_name == "avg") %>%
  dplyr::select(no_alcohol, alcohol, var_name) %>%
  mutate(no_alcohol = no_alcohol %>% round(2),
         alcohol = alcohol %>% round(2)) %>%
  rename(pct_no_alcohol = no_alcohol, 
         pct_alcohol = alcohol)

output_2 = sum_table_avg%>%
  left_join(sum_table_std, on = "var_name") %>%
  dplyr::select(var_name, count_no_alcohol, pct_no_alcohol, count_alcohol, pct_alcohol)

# Organize final output suitable for kable
rownames(output_2) = names_dict[output_2$var_name] %>% unname()
output_2 = output_2 %>% dplyr::select(-var_name)
```

```{r ind-sample-ttest, results="asis"}

test = t.test(df$pct_bachelor ~ df$drink)
test$p.value

var_list_2 = c("pct_bachelor", "md_hh_income")
ttest_list = c()

for(var in var_list_2) {
  this_test = t.test(df[[var]] ~ df$drink)
  this_p = this_test$p.value %>% round(3)
  ttest_list = c(ttest_list, this_p)
}

output_2 = output_2 %>% cbind(ttest_list) %>%
  rename("T-Test p-value" = ttest_list)

colnames(output_2) = c("Mean", "SD", "Mean", "SD", "T-Test p-value")

output_2 %>%
  kable(caption = "Table 3. Cross tabulations of the dependent variable and continuous predictors") %>%
  add_header_above(c(" ", "No alcohol involved" = 2, "Alcohol involved" = 2, "Independent Samples T-Test" = 1)) %>%
  kable_classic(full_width=FALSE, html_font="Cambria")
```

The table shows that both independent-samples T-tests produced a p-value greater than 0.05, meaning that the two continuous variables themselves are not significantly correlated with the dependent variable.

## Checking for multi-collinearity among the predictors

This section tests whether and how the predictors are inter-correlated with each other, although logistic regressions generally do not require for non-collinearity.

Table 4.
shows the correlation coefficient ($r$) between each pair of predictors, and Table 5.
presents the p-values.

```{r check-collin, results="asis"}

rcorr = 
  df %>% 
  dplyr::select(-record_id, -drink) %>% 
  as.matrix() %>% 
  rcorr(type = "pearson")

r_matrix = rcorr$r %>% round(2)
p_matrix = rcorr$P %>% round(2)

p_matrix[is.na(p_matrix)] = "/"

var_names = names_dict[colnames(r_matrix)] %>% unname()

colnames(r_matrix) = var_names
colnames(p_matrix) = var_names
rownames(r_matrix) = var_names
rownames(p_matrix) = var_names

r_matrix %>%
  kable(caption = "Table 4. Correlation matrix of predictors") %>%
  kable_classic(html_font="Cambria")

```

```{r check-collin-p, results="asis"}

p_matrix %>%
  kable(caption = "Table 5. Correlation matrix (p-values) of predictors") %>%
  kable_classic(html_font="Cambria")
```

The tables above shows that there is some collinearity between some predictors.
However, the correlations among the predictors are very weak.

# Logistic Regression Results


Having performed the exploratory analysis, this section focuses on the logistic regression itself.

```{r logistic_reg}

#Logistic Regression
reg_base <- glm(drink ~ fatal_injury + overturned + phone + speeding + aggressive + senior_driver + teen_driver + pct_bachelor + md_hh_income, data=df, family = "binomial")
summary(reg_base)

reg_bi_only <- glm(drink ~ fatal_injury + overturned + phone + speeding + aggressive + senior_driver + teen_driver, data=df, family = "binomial")
summary(reg_bi_only)


```

```{r sens_spec_cut_off_table, include=FALSE}

fit_df <- data.frame(observed = df$drink, fitted = reg_base$fitted.values)

cut_off <-  c(0.02, 0.03, 0.05, 0.07, 0.08, 0.09, 0.1, 0.15, 0.2, 0.5)

cut_off_df <- data.frame(Cut_Off_Value = double(),
                         Sensitivity = double(),
                         Specificity = double (),
                         Misclassification_Rate = double())

for (var in cut_off) {
  this_df <-  fit_df %>% 
  mutate(fit_binary = ifelse((fitted > var), 1, 0))
  
  cross_table  <- CrossTable(this_df$fit_binary, this_df$observed, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
  
  cut_off_df <- cut_off_df %>% add_row(
    Cut_Off_Value = var,
    Sensitivity = round(cross_table$prop.col[2,2], digits = 3),
    Specificity = round(cross_table$prop.col[1,1], digits = 3),
    Misclassification_Rate = round(
      (cross_table$t[1,2] + cross_table$t[2,1])/(cross_table$t[1,1] + cross_table$t[1,2] + cross_table$t[2,1] +cross_table$t[2,2]),
      digits = 3
    )
  )
}

```

```{r cut_off_table_present}

cut_off_df %>%
  kable(caption = "Table.5 Cut-Off") %>%
  kable_classic(full_width=FALSE, html_font="Cambria")

```

```{r roc}

library(plotROC)

# plot ROC, calculate AUC
ggplot(fit_df, aes(d = observed, m = fitted)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve",
       subtitle = paste("Area Under Curve (AUC): ", 
                       round(pROC::auc(fit_df$observed, fit_df$fitted), digits = 4)))+
  plotTheme()

```

```{r optimal_cut_off}
pred <- prediction(fit_df$fitted, fit_df$observed)
roc.perf = performance(pred, measure = "tpr", x.measure="fpr")

opt.cut = function(perf, pred){
  cut.ind = mapply(FUN=function(x, y, p){
    d = (x - 0)^2 + (y-1)^2
    ind = which(d == min(d))
    c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
      cutoff = p[[ind]])
  }, perf@x.values, perf@y.values, pred@cutoffs)
}
#This will print the optimal cut-off point and the corresponding
#specificity and sensitivity 
print(opt.cut(roc.perf, pred))


```
